{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import re\n",
    "import os\n",
    "\n",
    "try:\n",
    "    from tensorboardX import SummaryWriter\n",
    "except ModuleNotFoundError:\n",
    "    print(\"TensorboardX not available\")\n",
    "    pass\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'device = {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translating text\n",
    "\n",
    "How do you do this? There are many difficulties with different sentence lengths, different grammar or contextual information. In this notebook we will cover how to do this using sequence to sequence learning.\n",
    "\n",
    "![](img/hello-lead.png)\n",
    "\n",
    "## Sequence to sequence learning\n",
    "We will use pytorch to translate short sentences from French to English and vice versa\n",
    "\n",
    "Some concepts that will be covered:\n",
    "- Embeddings\n",
    "- Recurrent neural networks\n",
    "- Encoder / decoders\n",
    "- Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the needed data\n",
    "if not os.path.isfile('data.zip'):\n",
    "    ! curl -o data.zip https://download.pytorch.org/tutorial/data.zip && unzip data.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a quick view of the data.\n",
    "with open('data/eng-fra.txt') as f:\n",
    "    f.seek(1000)\n",
    "    print(f.read(200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data 0\n",
    "During the process, we need to interact with the languages quite often. We probably need to switch between words and indexes & vice versa. Therefore we need to keep some sort of mapping between the two. Something like:\n",
    "\n",
    "**indexes to word**\n",
    "```python\n",
    "{0: 'SOS',\n",
    " 1: 'EOS',\n",
    " 2: 'The'\n",
    " ...\n",
    " n: 'World'\n",
    "}\n",
    "```\n",
    "\n",
    "**words to indexes**\n",
    "```python\n",
    "{'SOS': 0,\n",
    " 'EOS': 1,\n",
    " 'The': 2\n",
    " ...\n",
    " 'World': n\n",
    "}\n",
    "```\n",
    "\n",
    "A nice way to do this, is creating an object that stores these mappings. This is already done for you. To check, go to: `utils.Language`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data 1\n",
    "\n",
    "What should we do?\n",
    "- Reading data from file\n",
    "- Make lowercase\n",
    "- Remove non-letter characters\n",
    "- Mark the end of the scentence\n",
    "- Mark the start of the scentence\n",
    "- Remove rare letters. (á, ò, ê)\n",
    "- ...\n",
    "- Translate words into numbers?\n",
    "\n",
    "This is already done for you. To check, go to: `preprocessing.normalize_string`, `preprocessing.unicode2ascii` and `preprocessing.read_lang_pairs`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data 2\n",
    "Since there are a lot of example sentences and we want to train something quickly in this short training, we'll trim the dataset to only contain relatively short and simple sentences. Here the maximum length is 10 words (that includes ending punctuation) and we're filtering to sentences that translate to the form \"I am\" or \"He is\" etc. (assuming that apostrophes are replaced earlier).\n",
    "\n",
    "In short:\n",
    "- only sentences < 10 words\n",
    "- only sentences that start with 'I am', 'He is' etc.\n",
    "\n",
    "This function is already created. To check it out, go to: `preprocessing.filter_pairs_eng2other`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data 3\n",
    "\n",
    "Next to this, it would be nice to create an object that contains the data. This object can help with several tasks, such as querying the data or shuffling the sentences. Something we need later on in the training process.\n",
    "\n",
    "We also need to:\n",
    "- Create a `Data` class\n",
    "\n",
    "This is already done for you. To check, go to: `utils.Data`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data 4\n",
    "\n",
    "Now we have to tie it all together. We need to:\n",
    "- Initialize the `Language` objects\n",
    "- Preprocess the sentence pairs\n",
    "- Filter out simple cases for this training\n",
    "\n",
    "We can of course put this in our `preprocessing` module as well, but for illustration purposes, we've put it below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Language, Data\n",
    "from preprocessing import read_lang_pairs, filter_pairs_eng2other\n",
    "\n",
    "\n",
    "def prepare_dataset(from_lang, to_lang):\n",
    "    \"\"\" Initializes the Language objects (still empty), creates the sentences pairs\n",
    "    and returns a Data object containing all languages and scentence pairs.\n",
    "    \"\"\"\n",
    "    pairs = read_lang_pairs(from_lang, to_lang)\n",
    "    print(f\"Read {len(pairs)} sentence pairs\")\n",
    "    \n",
    "    # Reduce data. We haven't got all day to train a model.\n",
    "    if from_lang != 'eng':\n",
    "         raise ValueError(f'No filter implemented for translation from {from_lang} to {to_lang}')\n",
    "    \n",
    "    pairs = filter_pairs_eng2other(pairs) \n",
    "    print(f\"Trimmed to {len(pairs)} sentence pairs\")\n",
    "    \n",
    "    input_lang = Language(from_lang)\n",
    "    output_lang = Language(to_lang)\n",
    "    # Add pairs to the languages\n",
    "    for pair in pairs:\n",
    "        input_lang.add_sentence(pair[0])\n",
    "        output_lang.add_sentence(pair[1])\n",
    "        \n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    \n",
    "    return input_lang, output_lang, Data(pairs, input_lang, output_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "eng, fra, data = prepare_dataset('eng', 'fra')\n",
    "print(f\"First data pair: {data.pairs[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence to sequence model overview\n",
    "So this is what we're going to build:\n",
    "\n",
    "![](img/seq2seq.png)\n",
    "\n",
    "Looking at the statistics printed above (of our simplified dataset), do you see any interesting output?\n",
    "- More French words than English\n",
    "- Quite a lot of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Encoder\n",
    "\n",
    "The encoder of a seq2seq network is a RNN that outputs some value for every word from the input sentence. For every input word the encoder outputs a vector and a hidden state, and uses the hidden state for the next input word. Every output could be seen as the context of the sentence up to that point.\n",
    "\n",
    "<img src=\"img/training_seq2seq_many2may.svg\" alt=\"drawing\" style=\"width:300px;\"/>\n",
    "\n",
    "As mentioned above, we have quite some words in our dictionaries. Therefore, it might be a good idea to create embeddings of our words since we're only passing context anyway.\n",
    "\n",
    "![](img/encoder-network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, n_words, embedding_size, hidden_size, device=device):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # create embedding layer\n",
    "        self.embedding = ...\n",
    "        \n",
    "        # create RNN\n",
    "        self.rnn = ...\n",
    "        \n",
    "        self.device = device\n",
    "        if device == 'cuda':\n",
    "            self.cuda()\n",
    "                    \n",
    "    def forward(self, x):\n",
    "        # - embed words\n",
    "        # - make shape (seq_length, batch_size, hidden_size)\n",
    "        dense_vector = ...\n",
    "\n",
    "        # init hidden layer at beginning of sequence --> SOS\n",
    "        # 'h' shape (what should the shape be?)\n",
    "        h = ...\n",
    "        \n",
    "        # run through rnn\n",
    "        x, h = ...\n",
    "\n",
    "        return x, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_words': '<fill>',\n",
    "    'embedding_size': '<fill>',\n",
    "    'hidden_size': '<fill>',\n",
    "    'device': device\n",
    "}        \n",
    "\n",
    "m = Encoder(**params)\n",
    "\n",
    "eng_sentence = data.pairs[0][0]\n",
    "sentence = torch.tensor(eng.translate_words(eng_sentence), device=device)\n",
    "enc_out, enc_hidden = m(sentence)\n",
    "\n",
    "print(f\"Test sentence: '{eng_sentence}'\")\n",
    "print(f\"Test tensor  : {sentence}\")\n",
    "print(f\"output shape : {enc_out.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Decoder\n",
    "\n",
    "In the simplest seq2seq decoder we use only last output of the encoder. This last output is sometimes called the context vector as it encodes context from the entire sequence. This context vector is used as the initial hidden state of the decoder.\n",
    "\n",
    "At every step of decoding, the decoder is given an input token and hidden state. The initial input token is the start-of-string <SOS> token, and the first hidden state is the context vector (the encoder’s last hidden state).\n",
    "    \n",
    "![](img/decoder-network-adapted.png)\n",
    "    \n",
    "\n",
    "The power of this model lies in the fact that it can map sequences of different lengths to each other. As you can see the inputs and outputs are not correlated and their lengths can differ. This opens a whole new range of problems which can now be solved using such architecture.    \n",
    "    \n",
    "<img src=\"img/unfolded-encoder-decoder.png\" alt=\"drawing\" style=\"width:500px;float: left;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size, output_size, device=device):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder = 'simple'\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # create embedding layer.\n",
    "        # question: what is the input size?\n",
    "        self.embedding = ...\n",
    "        \n",
    "        # create RNN\n",
    "        self.rnn = ...\n",
    "        \n",
    "        # create Layer to generate output\n",
    "        self.out = ...\n",
    "        \n",
    "        self.device = device\n",
    "        if device == 'cuda':\n",
    "            self.cuda()\n",
    "            \n",
    "    def forward(self, word, h):\n",
    "        # Make embedding of incoming word\n",
    "        word_embedding = ...\n",
    "        \n",
    "        # Map from shape (seq_len, embedding_size) to (seq_len, batch, embedding_size)\n",
    "        # Note: seq_len is the number of words in the sentence\n",
    "        x, h = ...\n",
    "        x = ...\n",
    "\n",
    "        return x, h\n",
    "\n",
    "params = {\n",
    "    'embedding_size': '<fill>',\n",
    "    'hidden_size': '<fill>',\n",
    "    'output_size': '<fill>',\n",
    "    'device': device\n",
    "}           \n",
    "\n",
    "m = Decoder(**params)\n",
    "m.train(False)\n",
    "out, hidden = m(torch.tensor([1]) ,torch.zeros(1, 1, 20))\n",
    "out.size(), hidden.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is wrong with the simple decoder?\n",
    "\n",
    "![](img/seq2seq.png)\n",
    "![](img/vanishing_context.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution: Attention\n",
    "<img src=\"img/seq2seq-attn.png\" alt=\"drawing\" style=\"height:400px;\"/>\n",
    "\n",
    "![](img/attention-decoder-network-adapted.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionDecoder(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size, output_size, dropout=0.1, max_length=10, device=device):\n",
    "        super(AttentionDecoder, self).__init__()\n",
    "        self.decoder = 'attention'\n",
    "        \n",
    "        # set properties\n",
    "        # question: Why this max_lenght?\n",
    "        self.max_length = max_length\n",
    "        self.device = device\n",
    "        \n",
    "        # create embedding layer\n",
    "        self.embedding = \n",
    "        \n",
    "        # Create seperate neural network to learn the attention weights\n",
    "        self.attention_weights = \n",
    "\n",
    "        # Combine attiontion weights\n",
    "        self.attention_combine = \n",
    "\n",
    "        # Create RNN\n",
    "        self.rnn = \n",
    "        \n",
    "        # create Layer to generate output\n",
    "        self.out = \n",
    "        \n",
    "        if device == 'cuda':\n",
    "            self.cuda()\n",
    "        \n",
    "    def forward(self, word, h, encoder_outputs):\n",
    "        # - Make embedding of word\n",
    "        # - Map from shape to (seq_len, batch, embedding_size) \n",
    "        # Note: seq length is the number of words in the sentence\n",
    "        word_embedding = ...\n",
    "        \n",
    "        # Concatenate the word embedding and the last hidden state, so that attention weights can be determined.\n",
    "        x = ...\n",
    "        \n",
    "        # apply attention\n",
    "        attention_weights = ...\n",
    "        \n",
    "        # Combine attention weights with encoder outputs (hint: torch.bmm)\n",
    "        x = ... \n",
    "\n",
    "        # Combine attention with input\n",
    "        x = ...\n",
    "    \n",
    "        # Generate (sequence) output\n",
    "        x, h = ...\n",
    "        x = ...\n",
    "        \n",
    "        return x, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_words': '<fill>',\n",
    "    'embedding_size': '<fill>',\n",
    "    'hidden_size': '<fill>',\n",
    "    'device': device\n",
    "}\n",
    "\n",
    "enc      = Encoder(**params)\n",
    "sentence = torch.tensor([1, 23, 9], device=device)\n",
    "out, h   = enc(sentence)\n",
    "print(\"out.shape:\", out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question:\n",
    "Who can think of a problem caused by attention?\n",
    "(hint: problem in the communication between encoder/decoder?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 10  # max sentence length\n",
    "encoder_outputs = ...\n",
    "print(f'encoder_outputs.shape: {encoder_outputs.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'embedding_size': '<fill>',\n",
    "    'hidden_size': '<fill>',\n",
    "    'output_size': '<fill>',\n",
    "    'device': device\n",
    "}\n",
    "a_dec = AttentionDecoder(**params)\n",
    "a_dec(torch.tensor([1], device=device), h, encoder_outputs)[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility function to run the decoder & calculate the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_decoder_loss(decoder, criterion, sentence, h, teacher_forcing=False, encoder_outputs=None):\n",
    "    loss = 0\n",
    "    word = torch.tensor([0], device=device) # <SOS>\n",
    "    for j in range(sentence.shape[0]):\n",
    "        if decoder.decoder == 'attention':\n",
    "            x, h = decoder(word, h, encoder_outputs)\n",
    "        else:\n",
    "            x, h = decoder(word, h)\n",
    "\n",
    "        loss += criterion(x.view(1, -1), sentence[j].view(-1))\n",
    "        if teacher_forcing:\n",
    "            word = sentence[j]\n",
    "        else:\n",
    "            word = x.argmax().detach()\n",
    "        if word.item() == 1: # <EOS>\n",
    "            break\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size        = 100\n",
    "context_vector_size   = 256\n",
    "\n",
    "enc_params = {\n",
    "    'n_words': '<fill>',\n",
    "    'embedding_size': '<fill>'\n",
    "    'hidden_size': '<fill>',\n",
    "    'device': device\n",
    "}\n",
    "encoder = Encoder(**enc_params)\n",
    "\n",
    "dec_params = {\n",
    "    'embedding_size': '<fill>',\n",
    "    'hidden_size': '<fill>',\n",
    "    'output_size': '<fill>',\n",
    "    'device': device\n",
    "}\n",
    "# dec = Decoder(**params)\n",
    "decoder = AttentionDecoder(**dec_params)\n",
    "\n",
    "if 'SummaryWriter' in globals():\n",
    "    writer = SummaryWriter('tb/train-3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs                = '<fill>'\n",
    "teacher_forcing_ratio = '<fill>'\n",
    "\n",
    "def train(encoder, decoder):\n",
    "    # Criterion\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    # Optimizers\n",
    "    optim_encoder = torch.optim.SGD(encoder.parameters(), lr=0.01)\n",
    "    optim_decoder = torch.optim.SGD(decoder.parameters(), lr=0.01)  \n",
    "    \n",
    "    # Models\n",
    "    encoder.train(True)\n",
    "    decoder.train(True)\n",
    "\n",
    "    # Train loop\n",
    "    for epoch in range(epochs):\n",
    "        data.shuffle()\n",
    "        for i in range(data.pairs.shape[0]):\n",
    "            optim_decoder.zero_grad()\n",
    "            optim_encoder.zero_grad()\n",
    "            \n",
    "            pair = data.idx_pairs[i]\n",
    "            eng_sentence = torch.tensor(pair[0], device=device)\n",
    "            fra_sentence = torch.tensor(pair[1], device=device)\n",
    "\n",
    "            # Encode the input language\n",
    "            out, h = ...    \n",
    "            \n",
    "            # pad encoder outputs with zeros if decoder uses attention\n",
    "            encoder_outputs = ...\n",
    "            \n",
    "            # implement teacher_forcing\n",
    "            teacher_forcing = ...\n",
    "            \n",
    "            # hint: use our run_decoder method!\n",
    "            loss = ...\n",
    "            loss.backward()\n",
    "            \n",
    "            if 'SummaryWriter' in globals():\n",
    "                writer.add_scalar('loss', loss.cpu().item() / (len(fra_sentence)))\n",
    "\n",
    "            optim_decoder.step()\n",
    "            optim_encoder.step()\n",
    "\n",
    "        print(f'epoch {epoch}')\n",
    "\n",
    "train(encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or load a pretrained model\n",
    "Only 10 epochs, trained by me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = Encoder(eng.n_words, embedding_size, context_vector_size)\n",
    "# encoder.load_state_dict(torch.load('models/encoder_10_epochs.pt', map_location=device))\n",
    "\n",
    "# decoder = AttentionDecoder(embedding_size, context_vector_size, fra.n_words)\n",
    "# decoder.load_state_dict(torch.load('models/decoder_10_epochs.pt', map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start translating some sentences from English to French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(start, end):\n",
    "    for i in range(start, end):\n",
    "        pair = data.idx_pairs[i]\n",
    "        eng_sentence = torch.tensor(pair[0], device=device)\n",
    "        fra_sentence = torch.tensor(pair[1], device=device)\n",
    "\n",
    "        print('English sentence:\\t', ' '.join([eng.index2word[i.item()] for i in eng_sentence[:-1]]))\n",
    "        print('French sentence:\\t', ' '.join([fra.index2word[i.item()] for i in fra_sentence[:-1]]))\n",
    "\n",
    "        # Encode the input language\n",
    "        out, h = encoder(eng_sentence)        \n",
    "        encoder_outputs = torch.zeros(max_length, out.shape[-1], device=device)\n",
    "        encoder_outputs[:out.shape[0], :out.shape[-1]] = out.view(out.shape[0], -1)\n",
    "        \n",
    "        word = torch.tensor([0], device=device) # <SOS>\n",
    "  \n",
    "        translation = []\n",
    "        for j in range(eng_sentence.shape[0]):\n",
    "            x, h = decoder(word, h, encoder_outputs=encoder_outputs)\n",
    "  \n",
    "            word = x.argmax().detach()\n",
    "            translation.append(word.cpu().data.tolist())\n",
    "\n",
    "            if word.item() == 1: # <EOS>\n",
    "                break\n",
    "        print('\\nModel translation:\\t', ' '.join([fra.index2word[i] for i in translation][:-1]), '\\n' + '-'*50)\n",
    "        \n",
    "translate(0, 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
