{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import re\n",
    "import os\n",
    "\n",
    "try:\n",
    "    from tensorboardX import SummaryWriter\n",
    "except ModuleNotFoundError:\n",
    "    print(\"TensorboardX not available\")\n",
    "    pass\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'device = {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translating text\n",
    "\n",
    "How do you do this? There are many difficulties with different sentence lengths, different grammar or contextual information. In this notebook we will cover how to do this using sequence to sequence learning.\n",
    "\n",
    "![](img/hello-lead.png)\n",
    "\n",
    "## Sequence to sequence learning\n",
    "We will use pytorch to translate short sentences from French to English and vice versa\n",
    "\n",
    "Some concepts that will be covered:\n",
    "- Embeddings\n",
    "- Recurrent neural networks\n",
    "- Encoder / decoders\n",
    "- Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the needed data\n",
    "if not os.path.isfile('data.zip'):\n",
    "    ! curl -o data.zip https://download.pytorch.org/tutorial/data.zip && unzip data.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " de question !\n",
      "Really?\tVraiment ?\n",
      "Really?\tVrai ?\n",
      "Really?\tAh bon ?\n",
      "Thanks.\tMerci !\n",
      "We try.\tOn essaye.\n",
      "We won.\tNous avons gagné.\n",
      "We won.\tNous gagnâmes.\n",
      "We won.\tNous l'avons emporté.\n",
      "We won.\tNous l'empor\n"
     ]
    }
   ],
   "source": [
    "# Take a quick view of the data.\n",
    "with open('data/eng-fra.txt') as f:\n",
    "    f.seek(1000)\n",
    "    print(f.read(200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data 0\n",
    "During the process, we need to interact with the languages quite often. We probably need to switch between words and indexes & vice versa. Therefore we need to keep some sort of mapping between the two. Something like:\n",
    "\n",
    "**indexes to word**\n",
    "```python\n",
    "{0: 'SOS',\n",
    " 1: 'EOS',\n",
    " 2: 'The'\n",
    " ...\n",
    " n: 'World'\n",
    "}\n",
    "```\n",
    "\n",
    "**words to indexes**\n",
    "```python\n",
    "{'SOS': 0,\n",
    " 'EOS': 1,\n",
    " 'The': 2\n",
    " ...\n",
    " 'World': n\n",
    "}\n",
    "```\n",
    "\n",
    "A nice way to do this, is creating an object that stores these mappings. This is already done for you. To check, go to: `utils.Language`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data 1\n",
    "\n",
    "What should we do?\n",
    "- Reading data from file\n",
    "- Make lowercase\n",
    "- Remove non-letter characters\n",
    "- Mark the end of the scentence\n",
    "- Mark the start of the scentence\n",
    "- Remove rare letters. (á, ò, ê)\n",
    "- ...\n",
    "- Translate words into numbers?\n",
    "\n",
    "This is already done for you. To check, go to: `preprocessing.normalize_string`, `preprocessing.unicode2ascii` and `preprocessing.read_lang_pairs`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data 2\n",
    "Since there are a lot of example sentences and we want to train something quickly in this short training, we'll trim the dataset to only contain relatively short and simple sentences. Here the maximum length is 10 words (that includes ending punctuation) and we're filtering to sentences that translate to the form \"I am\" or \"He is\" etc. (assuming that apostrophes are replaced earlier).\n",
    "\n",
    "In short:\n",
    "- only sentences < 10 words\n",
    "- only sentences that start with 'I am', 'He is' etc.\n",
    "\n",
    "This function is already created. To check it out, go to: `preprocessing.filter_pairs_eng2other`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data 3\n",
    "\n",
    "Next to this, it would be nice to create an object that contains the data. This object can help with several tasks, such as querying the data or shuffling the sentences. Something we need later on in the training process.\n",
    "\n",
    "We also need to:\n",
    "- Create a `Data` class\n",
    "\n",
    "This is already done for you. To check, go to: `utils.Data`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data 4\n",
    "\n",
    "Now we have to tie it all together. We need to:\n",
    "- Initialize the `Language` objects\n",
    "- Preprocess the sentence pairs\n",
    "- Filter out simple cases for this training\n",
    "\n",
    "We can of course put this in our `preprocessing` module as well, but for illustration purposes, we've put it below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Language, Data\n",
    "from preprocessing import read_lang_pairs, filter_pairs_eng2other\n",
    "\n",
    "\n",
    "def prepare_dataset(from_lang, to_lang):\n",
    "    \"\"\" Initializes the Language objects (still empty), creates the sentences pairs\n",
    "    and returns a Data object containing all languages and scentence pairs.\n",
    "    \"\"\"\n",
    "    pairs = read_lang_pairs(from_lang, to_lang)\n",
    "    print(f\"Read {len(pairs)} sentence pairs\")\n",
    "    \n",
    "    # Reduce data. We haven't got all day to train a model.\n",
    "    if from_lang != 'eng':\n",
    "         raise ValueError(f'No filter implemented for translation from {from_lang} to {to_lang}')\n",
    "    \n",
    "    pairs = filter_pairs_eng2other(pairs) \n",
    "    print(f\"Trimmed to {len(pairs)} sentence pairs\")\n",
    "    \n",
    "    input_lang = Language(from_lang)\n",
    "    output_lang = Language(to_lang)\n",
    "    # Add pairs to the languages\n",
    "    for pair in pairs:\n",
    "        input_lang.add_sentence(pair[0])\n",
    "        output_lang.add_sentence(pair[1])\n",
    "        \n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    \n",
    "    return input_lang, output_lang, Data(pairs, input_lang, output_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10853 sentence pairs\n",
      "Counted words:\n",
      "eng 2922\n",
      "fra 4486\n",
      "First data pair: ['i m EOS' 'j ai ans EOS']\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "eng, fra, data = prepare_dataset('eng', 'fra')\n",
    "print(f\"First data pair: {data.pairs[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence to sequence model overview\n",
    "So this is what we're going to build:\n",
    "\n",
    "![](img/seq2seq.png)\n",
    "\n",
    "Looking at the statistics printed above (of our simplified dataset), do you see any interesting output?\n",
    "- More French words than English\n",
    "- Quite a lot of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Encoder\n",
    "\n",
    "The encoder of a seq2seq network is a RNN that outputs some value for every word from the input sentence. For every input word the encoder outputs a vector and a hidden state, and uses the hidden state for the next input word. Every output could be seen as the context of the sentence up to that point.\n",
    "\n",
    "<img src=\"img/training_seq2seq_many2may.svg\" alt=\"drawing\" style=\"width:300px;\"/>\n",
    "\n",
    "As mentioned above, we have quite some words in our dictionaries. Therefore, it might be a good idea to create embeddings of our words since we're only passing context anyway.\n",
    "\n",
    "![](img/encoder-network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, n_words, embedding_size, hidden_size, device=device):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        # The word embeddings will also be trained simultaneously with the NN weights\n",
    "        # To freeze them --> m.embedding.weight.requires_grad = False\n",
    "        \n",
    "        # from vocab_size, to embedding_size\n",
    "        self.embedding = nn.Embedding(n_words, embedding_size)  \n",
    "        \n",
    "        # input for rnn is now in shape embedding size, output is our hidden size\n",
    "        self.rnn = nn.GRU(embedding_size, hidden_size)\n",
    "        \n",
    "        self.device = device\n",
    "        if device == 'cuda':\n",
    "            self.cuda()\n",
    "                    \n",
    "    def forward(self, x):\n",
    "        # 'x' shape (seq_length)\n",
    "        \n",
    "        # 'dense_vector' shape (seq_length, batch_size, hidden_size)\n",
    "        dense_vector = self.embedding(x).view(x.shape[0], 1, -1)\n",
    "        \n",
    "        # init hidden layer at beginning of sequence --> SOS\n",
    "        # 'h' shape (seq_length, batch_size, hidden_size)\n",
    "        h = torch.zeros(1, 1, self.hidden_size, device=self.device)\n",
    "\n",
    "        # 'x' shape (seq_length, batch_size, hidden_size)\n",
    "        x, h = self.rnn(dense_vector, h)\n",
    "\n",
    "        return x, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sentence: 'i m EOS'\n",
      "Test tensor  : tensor([2, 3, 1])\n",
      "output shape : torch.Size([3, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'n_words': eng.n_words,\n",
    "    'embedding_size': 10,\n",
    "    'hidden_size': 2,\n",
    "    'device': device\n",
    "}        \n",
    "\n",
    "m = Encoder(**params)\n",
    "\n",
    "eng_sentence = data.pairs[0][0]\n",
    "sentence = torch.tensor(eng.translate_words(eng_sentence), device=device)\n",
    "enc_out, enc_hidden = m(sentence)\n",
    "\n",
    "print(f\"Test sentence: '{eng_sentence}'\")\n",
    "print(f\"Test tensor  : {sentence}\")\n",
    "print(f\"output shape : {enc_out.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Decoder\n",
    "\n",
    "In the simplest seq2seq decoder we use only last output of the encoder. This last output is sometimes called the context vector as it encodes context from the entire sequence. This context vector is used as the initial hidden state of the decoder.\n",
    "\n",
    "At every step of decoding, the decoder is given an input token and hidden state. The initial input token is the start-of-string <SOS> token, and the first hidden state is the context vector (the encoder’s last hidden state).\n",
    "    \n",
    "![](img/decoder-network-adapted.png)\n",
    "    \n",
    "\n",
    "The power of this model lies in the fact that it can map sequences of different lengths to each other. As you can see the inputs and outputs are not correlated and their lengths can differ. This opens a whole new range of problems which can now be solved using such architecture.    \n",
    "    \n",
    "<img src=\"img/unfolded-encoder-decoder.png\" alt=\"drawing\" style=\"width:500px;float: left;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 4486]), torch.Size([1, 1, 20]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size, output_size, device=device):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder = 'simple'\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # embed from output_size to embedding size. SOS as starting token, in shape output size!\n",
    "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
    "\n",
    "        self.rnn = nn.GRU(embedding_size, hidden_size)\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "            nn.LogSoftmax(dim=2)\n",
    "        )\n",
    "        self.device = device\n",
    "        if device == 'cuda':\n",
    "            self.cuda()\n",
    "            \n",
    "    def forward(self, word, h):\n",
    "        \"\"\" Forward pass of the NN\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        word : torch.tensor\n",
    "            Last word or start of sentence token.\n",
    "        h : torch.tensor\n",
    "            Hidden state or context tensor.\n",
    "        \"\"\"\n",
    "        # Map from shape (seq_len, embedding_size) to (seq_len, batch, embedding_size)\n",
    "        # Note: seq_len is the number of words in the sentence\n",
    "        word_embedding = self.embedding(word).view(1, 1, -1)\n",
    "        \n",
    "        # x&h become (seq_len, batch, hidden_size)\n",
    "        x, h = self.rnn(word_embedding, h)\n",
    "        \n",
    "        # x becomes (seq_len, batch, vocab_size)\n",
    "        x = self.out(x)\n",
    "        return x, h\n",
    "\n",
    "params = {\n",
    "    'embedding_size': 10,\n",
    "    'hidden_size': 20,\n",
    "    'output_size': fra.n_words,\n",
    "    'device': device\n",
    "}  \n",
    "m = Decoder(**params)\n",
    "m.train(False)\n",
    "out, hidden = m(torch.tensor([1]) ,torch.zeros(1, 1, 20))\n",
    "out.size(), hidden.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is wrong with the simple decoder?\n",
    "\n",
    "![](img/seq2seq.png)\n",
    "![](img/vanishing_context.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution: Attention\n",
    "<img src=\"img/seq2seq-attn.png\" alt=\"drawing\" style=\"height:400px;\"/>\n",
    "\n",
    "![](img/attention-decoder-network-adapted.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionDecoder(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size, output_size, dropout=0.1, max_length=10, device=device):\n",
    "        super(AttentionDecoder, self).__init__()\n",
    "        self.decoder = 'attention'\n",
    "        #\n",
    "        self.max_length = max_length\n",
    "        self.device = device\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Embedding(output_size, embedding_size),\n",
    "        )\n",
    "        \n",
    "        # Seperate neural network to learn the attention weights\n",
    "        self.attention_weights = nn.Sequential(\n",
    "            nn.Linear(embedding_size + hidden_size, max_length),\n",
    "            nn.Softmax(dim=2)\n",
    "        )\n",
    "        self.attention_combine = nn.Sequential(\n",
    "            nn.Linear(hidden_size + embedding_size, hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "            nn.LogSoftmax(dim=2)\n",
    "        )\n",
    "        \n",
    "        if device == 'cuda':\n",
    "            self.cuda()\n",
    "        \n",
    "    def forward(self, word, h, encoder_outputs):\n",
    "        \"\"\"\n",
    "        :param word: (LongTensor) The word indices. This is the last activated word or \n",
    "        :param h: (tensor) The hidden state from the previous step. In the first step, the hidden state of the encoder.\n",
    "        :param encoder_outputs: (tensor) Zero padded (max_length, shape, shape) outputs from the encoder.\n",
    "        \"\"\"\n",
    "        # map from shape (seq_len, embedding_size) to (seq_len, batch, embedding_size) \n",
    "        # Note: seq length is the number of words in the sentence\n",
    "        word_embedding = self.embedding(word).view(1, 1, -1)\n",
    "        # Concatenate the word embedding and the last hidden state, so that attention weights can be determined.\n",
    "        x = torch.cat([word_embedding, h], dim=2)\n",
    "        \n",
    "        # attention applied\n",
    "        attention_weights = self.attention_weights(x)\n",
    "        \n",
    "        x = torch.bmm(attention_weights, encoder_outputs.unsqueeze(0))  # could also be done with matmul\n",
    "   \n",
    "        # attention combined\n",
    "        x = torch.cat((word_embedding, x), 2)\n",
    "        x = self.attention_combine(x)\n",
    "        \n",
    "        x, h = self.rnn(x, h)\n",
    "        x = self.out(x)\n",
    "\n",
    "        return x, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'embedding_size': 256,\n",
    "    'hidden_size': 256,\n",
    "    'output_size': 2,\n",
    "    'device': device\n",
    "}\n",
    "\n",
    "a_dec = AttentionDecoder(**params)\n",
    "\n",
    "# shape: (seq_len, batch, output_size)\n",
    "a_dec(torch.tensor([1], device=device), h, encoder_outputs)[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question:\n",
    "Who can think of a problem caused by attention?\n",
    "(hint: problem in the communication between encoder/decoder?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_outputs.shape: torch.Size([10, 256])\n"
     ]
    }
   ],
   "source": [
    "# in case sentence is shorter than max_length, pad with zeros\n",
    "max_length = 10\n",
    "encoder_outputs = torch.zeros(max_length, out.shape[-1], device=device)\n",
    "encoder_outputs[:out.shape[0], :out.shape[-1]] = out.view(out.shape[0], -1)\n",
    "\n",
    "# (padded) output shape is max_length x hidden_size\n",
    "print(f'encoder_outputs.shape: {encoder_outputs.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility function to run the decoder & calculate the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'embedding_size': 256,\n",
    "    'hidden_size': 256,\n",
    "    'output_size': 2,\n",
    "    'device': device\n",
    "}\n",
    "\n",
    "a_dec = AttentionDecoder(**params)\n",
    "\n",
    "# shape: (seq_len, batch, output_size)\n",
    "a_dec(torch.tensor([1], device=device), h, encoder_outputs)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_decoder_loss(decoder, criterion, sentence, h, teacher_forcing=False, encoder_outputs=None):\n",
    "    loss = 0\n",
    "    word = torch.tensor([0], device=device) # <SOS>\n",
    "    for j in range(sentence.shape[0]):\n",
    "        if decoder.decoder == 'attention':\n",
    "            x, h = decoder(word, h, encoder_outputs)\n",
    "        else:\n",
    "            x, h = decoder(word, h)\n",
    "\n",
    "        loss += criterion(x.view(1, -1), sentence[j].view(-1))\n",
    "        if teacher_forcing:\n",
    "            word = sentence[j]\n",
    "        else:\n",
    "            word = x.argmax().detach()\n",
    "        if word.item() == 1: # <EOS>\n",
    "            break\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size        = 100\n",
    "context_vector_size   = 256\n",
    "\n",
    "enc_params = {\n",
    "    'n_words': eng.n_words,\n",
    "    'embedding_size': embedding_size,\n",
    "    'hidden_size': context_vector_size,\n",
    "    'device': device\n",
    "}\n",
    "encoder = Encoder(**enc_params)\n",
    "\n",
    "dec_params = {\n",
    "    'embedding_size': embedding_size,\n",
    "    'hidden_size': context_vector_size,\n",
    "    'output_size': fra.n_words,\n",
    "    'device': device\n",
    "}\n",
    "# decoder = Decoder(**dec_params)\n",
    "decoder = AttentionDecoder(**dec_params)\n",
    "\n",
    "if 'SummaryWriter' in globals():\n",
    "    writer = SummaryWriter('tb/train-3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs                = 10\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "def train(encoder, decoder):\n",
    "    # Criterion\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    # Optimizers\n",
    "    optim_encoder = torch.optim.SGD(encoder.parameters(), lr=0.01)\n",
    "    optim_decoder = torch.optim.SGD(decoder.parameters(), lr=0.01)  \n",
    "    \n",
    "    # Models\n",
    "    encoder.train(True)\n",
    "    decoder.train(True)\n",
    "\n",
    "    # Train loop\n",
    "    for epoch in range(epochs):\n",
    "        data.shuffle()\n",
    "        for i in range(data.pairs.shape[0]):\n",
    "            optim_decoder.zero_grad()\n",
    "            optim_encoder.zero_grad()\n",
    "            \n",
    "            pair = data.idx_pairs[i]\n",
    "            eng_sentence = torch.tensor(pair[0], device=device)\n",
    "            fra_sentence = torch.tensor(pair[1], device=device)\n",
    "\n",
    "            # Encode the input language\n",
    "            # out and h shapes are (seq_length, batch_size, context_vec_size)\n",
    "            out, h = encoder(eng_sentence)\n",
    "            \n",
    "            # pad encoder outputs with zeros\n",
    "            encoder_outputs = torch.zeros(max_length, out.shape[-1], device=device)\n",
    "            \n",
    "            if decoder.decoder == 'attention':\n",
    "                 # padd and remove batch dim\n",
    "                encoder_outputs[:out.shape[0], :out.shape[-1]] = out.view(out.shape[0], -1)\n",
    "            \n",
    "            # implement teacher_forcing\n",
    "            teacher_forcing = np.random.rand() < teacher_forcing_ratio\n",
    "            loss = calc_decoder_loss(decoder, criterion, fra_sentence, h, teacher_forcing, encoder_outputs)\n",
    "            loss.backward()\n",
    "            \n",
    "            if 'SummaryWriter' in globals():\n",
    "                writer.add_scalar('loss', loss.cpu().item() / (len(fra_sentence)))\n",
    "\n",
    "            optim_decoder.step()\n",
    "            optim_encoder.step()\n",
    "\n",
    "        print(f'epoch {epoch}')\n",
    "\n",
    "train(encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or load a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Encoder(eng.n_words, embedding_size, context_vector_size)\n",
    "encoder.load_state_dict(torch.load('models/encoder_10_epochs.pt', map_location=device))\n",
    "\n",
    "decoder = AttentionDecoder(embedding_size, context_vector_size, fra.n_words)\n",
    "decoder.load_state_dict(torch.load('models/decoder_10_epochs.pt', map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start translating some sentences from English to French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English sentence:\t i m\n",
      "French sentence:\t j ai ans\n",
      "\n",
      "Model translation:\t je suis \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m ok\n",
      "French sentence:\t je vais bien\n",
      "\n",
      "Model translation:\t ca bien \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m ok\n",
      "French sentence:\t ca va\n",
      "\n",
      "Model translation:\t ca bien \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m fat\n",
      "French sentence:\t je suis gras\n",
      "\n",
      "Model translation:\t je suis gras \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m fat\n",
      "French sentence:\t je suis gros\n",
      "\n",
      "Model translation:\t je suis gras \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m fit\n",
      "French sentence:\t je suis en forme\n",
      "\n",
      "Model translation:\t je suis en \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m hit\n",
      "French sentence:\t je suis touche\n",
      "\n",
      "Model translation:\t je suis touchee \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m hit\n",
      "French sentence:\t je suis touchee\n",
      "\n",
      "Model translation:\t je suis touchee \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m ill\n",
      "French sentence:\t je suis malade\n",
      "\n",
      "Model translation:\t je suis malade \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m sad\n",
      "French sentence:\t je suis triste\n",
      "\n",
      "Model translation:\t je suis triste \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m shy\n",
      "French sentence:\t je suis timide\n",
      "\n",
      "Model translation:\t je suis timide \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m wet\n",
      "French sentence:\t je suis mouille\n",
      "\n",
      "Model translation:\t je suis mouille \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m wet\n",
      "French sentence:\t je suis mouillee\n",
      "\n",
      "Model translation:\t je suis mouille \n",
      "--------------------------------------------------\n",
      "English sentence:\t he s wet\n",
      "French sentence:\t il est mouille\n",
      "\n",
      "Model translation:\t il est mouille \n",
      "--------------------------------------------------\n",
      "English sentence:\t i am fat\n",
      "French sentence:\t je suis gras\n",
      "\n",
      "Model translation:\t je suis gras \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m back\n",
      "French sentence:\t je suis revenu\n",
      "\n",
      "Model translation:\t je suis en \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m back\n",
      "French sentence:\t me revoila\n",
      "\n",
      "Model translation:\t je suis en \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m bald\n",
      "French sentence:\t je suis chauve\n",
      "\n",
      "Model translation:\t je suis chauve \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m busy\n",
      "French sentence:\t je suis occupe\n",
      "\n",
      "Model translation:\t je suis occupe \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m busy\n",
      "French sentence:\t je suis occupee\n",
      "\n",
      "Model translation:\t je suis occupe \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m calm\n",
      "French sentence:\t je suis calme\n",
      "\n",
      "Model translation:\t je suis calme \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m cold\n",
      "French sentence:\t j ai froid\n",
      "\n",
      "Model translation:\t j ai froid \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m done\n",
      "French sentence:\t j en ai fini\n",
      "\n",
      "Model translation:\t j j j \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m fine\n",
      "French sentence:\t tout va bien\n",
      "\n",
      "Model translation:\t ca pour \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m fine\n",
      "French sentence:\t je vais bien\n",
      "\n",
      "Model translation:\t ca pour \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m fine\n",
      "French sentence:\t ca va\n",
      "\n",
      "Model translation:\t ca pour \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m free\n",
      "French sentence:\t je suis libre\n",
      "\n",
      "Model translation:\t je suis libre \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m free\n",
      "French sentence:\t je suis libre\n",
      "\n",
      "Model translation:\t je suis libre \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m free\n",
      "French sentence:\t je suis disponible\n",
      "\n",
      "Model translation:\t je suis libre \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m full\n",
      "French sentence:\t je suis repu\n",
      "\n",
      "Model translation:\t je suis rassasie \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m full\n",
      "French sentence:\t je suis rassasie\n",
      "\n",
      "Model translation:\t je suis rassasie \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m glad\n",
      "French sentence:\t je suis content\n",
      "\n",
      "Model translation:\t je suis content \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m home\n",
      "French sentence:\t je suis chez moi\n",
      "\n",
      "Model translation:\t je suis chez \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m late\n",
      "French sentence:\t je suis en retard\n",
      "\n",
      "Model translation:\t je suis en \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m lazy\n",
      "French sentence:\t je suis paresseux\n",
      "\n",
      "Model translation:\t je suis faineante \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m lazy\n",
      "French sentence:\t je suis faineant\n",
      "\n",
      "Model translation:\t je suis faineante \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m lazy\n",
      "French sentence:\t je suis paresseuse\n",
      "\n",
      "Model translation:\t je suis faineante \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m lazy\n",
      "French sentence:\t je suis faineante\n",
      "\n",
      "Model translation:\t je suis faineante \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m okay\n",
      "French sentence:\t je vais bien\n",
      "\n",
      "Model translation:\t je vais bien \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m okay\n",
      "French sentence:\t je me porte bien\n",
      "\n",
      "Model translation:\t je vais bien \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m safe\n",
      "French sentence:\t je suis en securite\n",
      "\n",
      "Model translation:\t je suis en \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m sick\n",
      "French sentence:\t je suis malade\n",
      "\n",
      "Model translation:\t je suis malade \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m sure\n",
      "French sentence:\t j en suis certain\n",
      "\n",
      "Model translation:\t je suis certain \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m sure\n",
      "French sentence:\t je suis certain\n",
      "\n",
      "Model translation:\t je suis certain \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m sure\n",
      "French sentence:\t j en suis sur\n",
      "\n",
      "Model translation:\t je suis certain \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m sure\n",
      "French sentence:\t j en suis sure\n",
      "\n",
      "Model translation:\t je suis certain \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m tall\n",
      "French sentence:\t je suis grande\n",
      "\n",
      "Model translation:\t je suis grand \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m thin\n",
      "French sentence:\t je suis mince\n",
      "\n",
      "Model translation:\t je suis mince \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m tidy\n",
      "French sentence:\t je suis ordonne\n",
      "\n",
      "Model translation:\t je suis ordonnee \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m tidy\n",
      "French sentence:\t je suis ordonnee\n",
      "\n",
      "Model translation:\t je suis ordonnee \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m ugly\n",
      "French sentence:\t je suis laid\n",
      "\n",
      "Model translation:\t je suis laid \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m ugly\n",
      "French sentence:\t je suis laide\n",
      "\n",
      "Model translation:\t je suis laid \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m weak\n",
      "French sentence:\t je suis faible\n",
      "\n",
      "Model translation:\t je suis faible \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m well\n",
      "French sentence:\t je vais bien\n",
      "\n",
      "Model translation:\t je vais bien \n",
      "--------------------------------------------------\n",
      "English sentence:\t i m well\n",
      "French sentence:\t je me porte bien\n",
      "\n",
      "Model translation:\t je vais bien \n",
      "--------------------------------------------------\n",
      "English sentence:\t he is ill\n",
      "French sentence:\t il est malade\n",
      "\n",
      "Model translation:\t il est malade \n",
      "--------------------------------------------------\n",
      "English sentence:\t he is old\n",
      "French sentence:\t il est vieux\n",
      "\n",
      "Model translation:\t il est vieux \n",
      "--------------------------------------------------\n",
      "English sentence:\t he s a dj\n",
      "French sentence:\t il est dj\n",
      "\n",
      "Model translation:\t il est un \n",
      "--------------------------------------------------\n",
      "English sentence:\t he s good\n",
      "French sentence:\t il est bon\n",
      "\n",
      "Model translation:\t il est bon \n",
      "--------------------------------------------------\n",
      "English sentence:\t he s lazy\n",
      "French sentence:\t il est paresseux\n",
      "\n",
      "Model translation:\t il est paresseux \n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def translate(start, end):\n",
    "    for i in range(start, end):\n",
    "        pair = data.idx_pairs[i]\n",
    "        eng_sentence = torch.tensor(pair[0], device=device)\n",
    "        fra_sentence = torch.tensor(pair[1], device=device)\n",
    "\n",
    "        print('English sentence:\\t', ' '.join([eng.index2word[i.item()] for i in eng_sentence[:-1]]))\n",
    "        print('French sentence:\\t', ' '.join([fra.index2word[i.item()] for i in fra_sentence[:-1]]))\n",
    "\n",
    "        # Encode the input language\n",
    "        out, h = encoder(eng_sentence)        \n",
    "        encoder_outputs = torch.zeros(max_length, out.shape[-1], device=device)\n",
    "        encoder_outputs[:out.shape[0], :out.shape[-1]] = out.view(out.shape[0], -1)\n",
    "        \n",
    "        word = torch.tensor([0], device=device) # <SOS>\n",
    "  \n",
    "        translation = []\n",
    "        for j in range(eng_sentence.shape[0]):\n",
    "            x, h = decoder(word, h, encoder_outputs=encoder_outputs)\n",
    "  \n",
    "            word = x.argmax().detach()\n",
    "            translation.append(word.cpu().data.tolist())\n",
    "\n",
    "            if word.item() == 1: # <EOS>\n",
    "                break\n",
    "        print('\\nModel translation:\\t', ' '.join([fra.index2word[i] for i in translation][:-1]), '\\n' + '-'*50)\n",
    "        \n",
    "translate(0, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
