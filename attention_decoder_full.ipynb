{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = cpu\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import re\n",
    "import os\n",
    "\n",
    "try:\n",
    "    from tensorboardX import SummaryWriter\n",
    "except ModuleNotFoundError:\n",
    "    print(\"TensorboardX not available\")\n",
    "    pass\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'device = {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translating text\n",
    "\n",
    "How do you do this? There are many difficulties with different sentence lengths, different grammar or contextual information. In this notebook we will cover how to do this using sequence to sequence learning.\n",
    "\n",
    "![](img/hello-lead.png)\n",
    "\n",
    "## Sequence to sequence learning\n",
    "We will use pytorch to translate short sentences from French to English and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the needed data\n",
    "if not os.path.isfile('data.zip'):\n",
    "    ! curl -o data.zip https://download.pytorch.org/tutorial/data.zip && unzip data.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " de question !\n",
      "Really?\tVraiment ?\n",
      "Really?\tVrai ?\n",
      "Really?\tAh bon ?\n",
      "Thanks.\tMerci !\n",
      "We try.\tOn essaye.\n",
      "We won.\tNous avons gagné.\n",
      "We won.\tNous gagnâmes.\n",
      "We won.\tNous l'avons emporté.\n",
      "We won.\tNous l'empor\n"
     ]
    }
   ],
   "source": [
    "# Take a quick view of the data.\n",
    "with open('data/eng-fra.txt') as f:\n",
    "    f.seek(1000)\n",
    "    print(f.read(200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data I\n",
    "\n",
    "* Create a Language class that maps indexes to words and words to indexes\n",
    "\n",
    "**indexes to word**\n",
    "```python\n",
    "{0: SOS,\n",
    " 1: EOS,\n",
    " 2: The\n",
    " ...\n",
    " n: World\n",
    "}\n",
    "```\n",
    "\n",
    "**words to indexes**\n",
    "```python\n",
    "{SOS: 0,\n",
    " EOS: 1,\n",
    " The: 2\n",
    " ...\n",
    " World: n\n",
    "}\n",
    "```\n",
    "\n",
    "* Implement functions to convert the letters to ASCII and remove rare letters. (á, ò, ê -> a, o, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Language:\n",
    "    \"\"\" Utility class that serves as a language dictionary \"\"\"\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        # Count how often a word occurs in the language data.\n",
    "        self.word2count = {}\n",
    "        # Words are mapped to indices and vice versa\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.word2index = {v:k for k, v in self.index2word.items()}\n",
    "        # Total word count\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def add_sentence(self, sentence):\n",
    "        \"\"\" Process words in a sentence string. \"\"\"\n",
    "        for word in sentence.split(' '):\n",
    "            self.add_word(word)\n",
    "\n",
    "    def add_word(self, word):\n",
    "        \"\"\" Process a word (e.g. put it in vocabulary and count) \"\"\"\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        elif word != 'SOS' and word != 'EOS':\n",
    "            self.word2count[word] += 1\n",
    "    \n",
    "    def translate_indexes(self, idx):\n",
    "        \"\"\" Takes in a vector of indices and returns the sentence. \"\"\"\n",
    "        return [self.index2word[i] for i in idx]\n",
    "    \n",
    "    def translate_words(self, words):\n",
    "        \"\"\" Takes in a vector of indices and returns the sentence. \"\"\"\n",
    "        return [self.word2index[w] for w in words.split(' ')]\n",
    "    \n",
    "    \n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicode2ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalize_string(s):\n",
    "    s = unicode2ascii(s.lower().strip())\n",
    "    s = re.sub(r\"\\s?[.!?]\", r\" EOS\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def read_langs(lang1, lang2):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "    \n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalize_string(s) for s in l.split('\\t')] for l in lines]\n",
    "    input_lang = Language(lang1)\n",
    "    output_lang = Language(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data II\n",
    "Since there are a lot of example sentences and we want to train something quickly, we'll trim the data set to only relatively short and simple sentences. \n",
    "Here the maximum length is 10 words (that includes ending punctuation) and we're filtering to sentences that translate to the form \"I am\" or \"He is\" etc. \n",
    "(accounting for apostrophes replaced earlier).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_pairs(pairs):\n",
    "    MAX_LENGTH = 10\n",
    "    \n",
    "    eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    "    )\n",
    "    \n",
    "    def filter_pair(p):\n",
    "        return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "            len(p[1].split(' ')) < MAX_LENGTH \\\n",
    "            and p[0].startswith(eng_prefixes)\n",
    "    return [pair for pair in pairs if filter_pair(pair)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data III\n",
    "\n",
    "Read the data from the text files, normalize the sentences, create the Language instances from the Language class and wrap the two languages in a Data class so we can shuffle the sentences and query them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10853 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 2922\n",
      "fra 4486\n",
      "First data pair: ['you re jealous EOS' 'tu es jalouse EOS']\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, pairs, lang_1, lang_2):\n",
    "        self.pairs = np.array(pairs)        \n",
    "        np.random.shuffle(self.pairs)\n",
    "        idx_1 = [[lang_1.word2index[word] for word in s.split(' ')] \n",
    "                               for s in self.pairs[:, 0]]\n",
    "        idx_2 = [[lang_2.word2index[word] for word in s.split(' ')]\n",
    "                               for s in self.pairs[:, 1]]\n",
    "        self.idx_pairs = np.array(list(zip(idx_1, idx_2)))\n",
    "        self.shuffle_idx = np.arange(len(pairs))\n",
    "                \n",
    "    def __str__(self):\n",
    "        return(self.pairs)\n",
    "    \n",
    "    def shuffle(self):\n",
    "        np.random.shuffle(self.shuffle_idx)\n",
    "        self.pairs = self.pairs[self.shuffle_idx]\n",
    "        self.idx_pairs = self.idx_pairs[self.shuffle_idx]      \n",
    "    \n",
    "def prepare_data(lang1, lang2):\n",
    "    # read_langs initialized the Language objects (still empty) and returns the pair sentences.\n",
    "    input_lang, output_lang, pairs = read_langs(lang1, lang2)\n",
    "    print(f\"Read {len(pairs)} sentence pairs\")\n",
    "    \n",
    "    # Reduce data. We haven't got all day to train a model.\n",
    "    pairs = filter_pairs(pairs) \n",
    "    print(f\"Trimmed to {len(pairs)} sentence pairs\")\n",
    "    print(\"Counting words...\")\n",
    "    \n",
    "    # Process the language pairs.\n",
    "    for pair in pairs:\n",
    "        input_lang.add_sentence(pair[0])\n",
    "        output_lang.add_sentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, Data(pairs, input_lang, output_lang)\n",
    "\n",
    "\n",
    "eng, fra, data = prepare_data('eng', 'fra')\n",
    "print(f\"First data pair: {data.pairs[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence to sequence model overview\n",
    "\n",
    "![](img/seq2seq.png)\n",
    "\n",
    "## The Encoder\n",
    "\n",
    "The encoder of a seq2seq network is a RNN that outputs some value for every word from the input sentence. For every input word the encoder outputs a vector and a hidden state, and uses the hidden state for the next input word. Every output could be seen as the context of the sentence up to that point.\n",
    "\n",
    "<img src=\"img/training_seq2seq_many2may.svg\" alt=\"drawing\" style=\"height:300px;float: left;\"/>\n",
    "\n",
    "![](img/encoder-network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sentence: we are even EOS\n",
      "Test tensor: tensor([ 75, 123, 125,   1])\n",
      "(raw) x = torch.Size([4])\n",
      "embedded x = torch.Size([4, 10])\n",
      "dense_vector = torch.Size([4, 1, 10])\n",
      "h init = torch.Size([1, 1, 2])\n",
      "h = torch.Size([1, 1, 2]), x = torch.Size([4, 1, 2])\n",
      "output shape: torch.Size([4, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, n_words, embedding_size, hidden_size, device=device):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        # The word embeddings will also be trained\n",
    "        # To freeze them --> m.embedding.weight.requires_grad = False\n",
    "        self.embedding = nn.Embedding(n_words, embedding_size)  \n",
    "        self.rnn = nn.GRU(embedding_size, hidden_size)\n",
    "        \n",
    "        self.device = device\n",
    "        if device == 'cuda':\n",
    "            self.cuda()\n",
    "                    \n",
    "    def forward(self, x):\n",
    "        print(f'(raw) x = {x.shape}')\n",
    "        print(f'embedded x = {self.embedding(x).shape}')\n",
    "\n",
    "        # shape (seq_length, batch_size, input_size)\n",
    "        dense_vector = self.embedding(x).view(x.shape[0], 1, -1)\n",
    "        print(f'dense_vector = {dense_vector.shape}')\n",
    "        \n",
    "        # init hidden layer at beginning of sequence --> SOS\n",
    "        h = torch.zeros(1, 1, self.hidden_size, device=self.device)\n",
    "        print(f'h init = {h.shape}')\n",
    "        \n",
    "        x, h = self.rnn(dense_vector, h)\n",
    "        print(f'h = {h.shape}, x = {x.shape}')\n",
    "\n",
    "        return x, h\n",
    "        \n",
    "\n",
    "m = Encoder(n_words=eng.n_words, \n",
    "            embedding_size=10, \n",
    "            hidden_size=2, \n",
    "            device=device)\n",
    "\n",
    "eng_sentence = data.pairs[0][0]\n",
    "print(f'Test sentence: {eng_sentence}')\n",
    "sentence = torch.tensor(eng.translate_words(eng_sentence), device=device)\n",
    "print(f'Test tensor: {sentence}')\n",
    "enc_out, enc_hidden = m(sentence)\n",
    "print(f'output shape: {enc_out.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Decoder\n",
    "\n",
    "In the simplest seq2seq decoder we use only last output of the encoder. This last output is sometimes called the context vector as it encodes context from the entire sequence. This context vector is used as the initial hidden state of the decoder.\n",
    "\n",
    "At every step of decoding, the decoder is given an input token and hidden state. The initial input token is the start-of-string <SOS> token, and the first hidden state is the context vector (the encoder’s last hidden state).\n",
    "    \n",
    "![](img/decoder-network-adapted.png)\n",
    "    \n",
    "\n",
    "The power of this model lies in the fact that it can map sequences of different lengths to each other. As you can see the inputs and outputs are not correlated and their lengths can differ. This opens a whole new range of problems which can now be solved using such architecture.    \n",
    "    \n",
    "<img src=\"img/unfolded-encoder-decoder.png\" alt=\"drawing\" style=\"width:500px;float: left;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 2922]), torch.Size([1, 1, 20]))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size, output_size, device=device):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder = 'simple'\n",
    "        self.hidden_size = hidden_size\n",
    "        # Lookup table for the last word activation.\n",
    "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
    "        self.rnn = nn.GRU(embedding_size, hidden_size)\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "            nn.LogSoftmax(dim=2)\n",
    "        )\n",
    "        self.device = device\n",
    "        if device == 'cuda':\n",
    "            self.cuda()\n",
    "            \n",
    "    def forward(self, word, h):\n",
    "        \"\"\" Forward pass of the NN\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        word : torch.tensor\n",
    "            Last word or start of sentence token.\n",
    "        h : torch.tensor\n",
    "            Hidden state or context tensor.\n",
    "        \"\"\"\n",
    "        # Map from shape (seq_len, embedding_size) to (seq_len, batch, embedding_size)\n",
    "        # Note: seq_len is the number of words in the sentence\n",
    "        word_embedding = self.embedding(word).view(1, 1, -1)\n",
    "        x, h = self.rnn(word_embedding, h)\n",
    "\n",
    "        return self.out(x), h\n",
    "    \n",
    "m = Decoder(embedding_size=10, \n",
    "            hidden_size=20, \n",
    "            output_size=eng.n_words,\n",
    "            device=device)\n",
    "m.train(False)\n",
    "out, hidden = m(torch.tensor([1]) ,torch.zeros(1, 1, 20))\n",
    "out.size(), hidden.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is wrong with the simple decoder?\n",
    "\n",
    "![](img/seq2seq.png)\n",
    "![](img/vanishing_context.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution: Attention\n",
    "![](img/attention-decoder-network-adapted.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(raw) x = torch.Size([3])\n",
      "embedded x = torch.Size([3, 256])\n",
      "dense_vector = torch.Size([3, 1, 256])\n",
      "h init = torch.Size([1, 1, 256])\n",
      "h = torch.Size([1, 1, 256]), x = torch.Size([3, 1, 256])\n",
      "out.shape: torch.Size([3, 1, 256])\n",
      "encoder_outputs.shape: torch.Size([10, 256])\n",
      "word tensor([1])\n",
      "word embedding torch.Size([1, 1, 256])\n",
      "before bmm torch.Size([1, 1, 512])\n",
      "attention_weights torch.Size([1, 1, 10])\n",
      "after bmm torch.Size([1, 1, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 2])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AttentionDecoder(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size, output_size, dropout=0.1, max_length=10, device=device):\n",
    "        super(AttentionDecoder, self).__init__()\n",
    "        self.decoder = 'attention'\n",
    "        self.max_length = max_length\n",
    "        self.device = device\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Embedding(output_size, embedding_size),\n",
    "        )\n",
    "        \n",
    "        # Seperate neural network to learn the attention weights\n",
    "        self.attention_weights = nn.Sequential(\n",
    "            nn.Linear(embedding_size + hidden_size, max_length),\n",
    "            nn.Softmax(2)\n",
    "        )\n",
    "        self.attention_combine = nn.Sequential(\n",
    "            nn.Linear(hidden_size + embedding_size, hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "            nn.LogSoftmax(2)\n",
    "        )\n",
    "        \n",
    "        if device == 'cuda':\n",
    "            self.cuda()\n",
    "        \n",
    "    def forward(self, word, h, encoder_outputs):\n",
    "        \"\"\"\n",
    "        :param word: (LongTensor) The word indices. This is the last activated word or \n",
    "        :param h: (tensor) The hidden state from the previous step. In the first step, the hidden state of the encoder.\n",
    "        :param encoder_outputs: (tensor) Zero padded (max_length, shape, shape) outputs from the encoder.\n",
    "        \"\"\"\n",
    "        # map from shape (seq_len, embedding_size) to (seq_len, batch, embedding_size) \n",
    "        # Note: seq length is the number of words in the sentence\n",
    "        print(\"word\", word)\n",
    "        word_embedding = self.embedding(word).view(1, 1, -1)\n",
    "        print(\"word embedding\", word_embedding.shape)\n",
    "        # Concatenate the word embedding and the last hidden state, so that attention weights can be determined.\n",
    "        x = torch.cat([word_embedding, h], dim=2)\n",
    "        \n",
    "        # attention applied\n",
    "        attention_weights = self.attention_weights(x)\n",
    "        print(\"before bmm\", x.shape)\n",
    "        print(\"attention_weights\", attention_weights.shape)\n",
    "        \n",
    "        x = torch.bmm(attention_weights, encoder_outputs.unsqueeze(0))  # could also be done with matmul\n",
    "        print(\"after bmm\", x.shape)\n",
    "   \n",
    "        # attention combined\n",
    "        x = torch.cat((word_embedding, x), 2)\n",
    "        x = self.attention_combine(x)\n",
    "        \n",
    "        x, h = self.rnn(x, h)\n",
    "        x = self.out(x)\n",
    "\n",
    "        return x, h\n",
    "    \n",
    "embedding_size = 256\n",
    "hidden_size    = 256\n",
    "max_length     = 10\n",
    "\n",
    "m        = Encoder(eng.n_words, embedding_size, hidden_size, device=device)\n",
    "sentence = torch.tensor([1, 23, 9], device=device)\n",
    "out, h   = m(sentence)\n",
    "print(\"out.shape:\", out.shape)\n",
    "\n",
    "# in case sentence is shorter than max_length, pad with zeros\n",
    "encoder_outputs = torch.zeros(max_length, out.shape[-1], device=device)\n",
    "encoder_outputs[:out.shape[0], :out.shape[-1]] = out.view(out.shape[0], -1)\n",
    "print(f'encoder_outputs.shape: {encoder_outputs.shape}')\n",
    "\n",
    "m = AttentionDecoder(embedding_size, hidden_size, output_size=2, device=device)\n",
    "m(torch.tensor([1], device=device), h, encoder_outputs)[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility function to run the decoder & calculate the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_decoder(decoder, criterion, sentence, h, teacher_forcing=False, encoder_outputs=None):\n",
    "    loss = 0\n",
    "    word = torch.tensor([0], device=device) # <SOS>\n",
    "    for j in range(sentence.shape[0]):\n",
    "        if decoder.decoder == 'attention':\n",
    "            x, h = decoder(word, h, encoder_outputs)\n",
    "        else:\n",
    "            x, h = decoder(word, h)\n",
    "\n",
    "        loss += criterion(x.view(1, -1), sentence[j].view(-1))\n",
    "        if teacher_forcing:\n",
    "            word = sentence[j]\n",
    "        else:\n",
    "            word = x.argmax().detach()\n",
    "        if word.item() == 1: # <EOS>\n",
    "            break\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs                = 10\n",
    "teacher_forcing_ratio = 0.5\n",
    "embedding_size        = 100\n",
    "context_vector_size   = 256\n",
    "\n",
    "encoder = Encoder(n_words=eng.n_words, \n",
    "                  embedding_size=embedding_size, \n",
    "                  hidden_size=context_vector_size)\n",
    "decoder = AttentionDecoder(embedding_size=embedding_size, \n",
    "                           hidden_size=context_vector_size, \n",
    "                           output_size=fra.n_words)\n",
    "\n",
    "if 'SummaryWriter' in globals():\n",
    "    writer = SummaryWriter('tb/train-3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zelf bouwen\n",
    "def train(encoder, decoder):\n",
    "    # Criterion\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    # Optimizers\n",
    "    optim_encoder = torch.optim.SGD(encoder.parameters(), lr=0.01)\n",
    "    optim_decoder = torch.optim.SGD(decoder.parameters(), lr=0.01)  \n",
    "    \n",
    "    # Models\n",
    "    encoder.train(True)\n",
    "    decoder.train(True)\n",
    "\n",
    "    # Train loop\n",
    "    for epoch in range(epochs):\n",
    "        data.shuffle()\n",
    "        for i in range(data.pairs.shape[0]):\n",
    "            optim_decoder.zero_grad()\n",
    "            optim_encoder.zero_grad()\n",
    "            \n",
    "            pair = data.idx_pairs[i]\n",
    "            eng_sentence = torch.tensor(pair[0], device=device)\n",
    "            fra_sentence = torch.tensor(pair[1], device=device)\n",
    "\n",
    "            # Encode the input language\n",
    "            out, h = encoder(eng_sentence)        \n",
    "            \n",
    "            # pad encoder outputs with zeros\n",
    "            encoder_outputs = torch.zeros(max_length, out.shape[-1], device=device)\n",
    "            if decoder.decoder == 'attention':\n",
    "                encoder_outputs[:out.shape[0], :out.shape[-1]] = out.view(out.shape[0], -1) # remove batch dim\n",
    "            \n",
    "            # implement teacher_forcing\n",
    "            teacher_forcing = np.random.rand() < teacher_forcing_ratio\n",
    "            loss = run_decoder(decoder, criterion, fra_sentence, h, teacher_forcing, encoder_outputs)\n",
    "            loss.backward()\n",
    "            \n",
    "            if 'SummaryWriter' in globals():\n",
    "                writer.add_scalar('loss', loss.cpu().item() / (len(fra_sentence)))\n",
    "\n",
    "            optim_decoder.step()\n",
    "            optim_encoder.step()\n",
    "\n",
    "        print(f'epoch {epoch}')\n",
    "\n",
    "train(encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or load a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = Encoder(eng.n_words, embedding_size, context_vector_size)\n",
    "# encoder.load_state_dict(torch.load('models/encoder_10_epochs.pt', map_location=device))\n",
    "\n",
    "# decoder = AttentionDecoder(embedding_size, context_vector_size, fra.n_words)\n",
    "# decoder.load_state_dict(torch.load('models/decoder_10_epochs.pt', map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start translating some sentences from English to French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(start, end):\n",
    "    for i in range(start, end):\n",
    "        pair = data.idx_pairs[i]\n",
    "        eng_sentence = torch.tensor(pair[0], device=device)\n",
    "        fra_sentence = torch.tensor(pair[1], device=device)\n",
    "\n",
    "        print('English sentence:\\t', ' '.join([eng.index2word[i.item()] for i in eng_sentence[:-1]]))\n",
    "        print('French sentence:\\t', ' '.join([fra.index2word[i.item()] for i in fra_sentence[:-1]]))\n",
    "\n",
    "        # Encode the input language\n",
    "        out, h = encoder(eng_sentence)        \n",
    "        encoder_outputs = torch.zeros(max_length, out.shape[-1], device=device)\n",
    "        encoder_outputs[:out.shape[0], :out.shape[-1]] = out.view(out.shape[0], -1)\n",
    "        \n",
    "        word = torch.tensor([0], device=device) # <SOS>\n",
    "  \n",
    "        translation = []\n",
    "        for j in range(eng_sentence.shape[0]):\n",
    "            x, h = decoder(word, h, encoder_outputs=encoder_outputs)\n",
    "  \n",
    "            word = x.argmax().detach()\n",
    "            translation.append(word.cpu().data.tolist())\n",
    "\n",
    "            if word.item() == 1: # <EOS>\n",
    "                break\n",
    "        print('\\nModel translation:\\t', ' '.join([fra.index2word[i] for i in translation][:-1]), '\\n' + '-'*50)\n",
    "        \n",
    "translate(0, 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
